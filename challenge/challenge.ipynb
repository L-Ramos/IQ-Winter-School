{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iQ Winter School 2018 on Machine Learning Applied to Quantitative Analysis of Medical Images\n",
    "## Hands-on Session 2 - Challenge\n",
    "\n",
    "### Your turn!\n",
    "\n",
    "Here you have the chance to beat the good old simplistic image processing techniques by applying what you've learned in the tutorial. We provide you with several help functions that you may use as you wish. Although these functions point you in the direction of using a patch-based CNN, feel free to implement your own ideas on how to approach the problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some imports\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import os\n",
    "import timeit\n",
    "\n",
    "from keras import metrics, optimizers\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "import skimage.segmentation\n",
    "import sklearn.feature_extraction.image\n",
    "import sklearn.model_selection\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from pylab import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Patch extraction functions. \n",
    "\n",
    "# Use these if you'd like to follow a patchwise classification approach:\n",
    "# the images are subdivided into patches, which are then fed into a classifier (eg, a CNN) \n",
    "# together with the label of its center pixel.\n",
    "        \n",
    "def Get_Patch(center_x,center_y,patch_s,image):\n",
    "    \"\"\"\n",
    "    Gets the patch with size patch_s at position (center_x, center_y) in the image\n",
    "    Input: \n",
    "        center_x: line position of the center pixel\n",
    "        center_y: col position of the center pixel\n",
    "        patch_s: patch size\n",
    "        image: whole image to extract patch from (img_size, img_size)\n",
    "    Output:\n",
    "        new_patch: an array of size [patch_s,patch_s]        \n",
    "    \"\"\"\n",
    "    \n",
    "    half_patch=int(patch_s/2)\n",
    "    \n",
    "    start_x=center_x-half_patch\n",
    "    start_y=center_y-half_patch\n",
    "    end_x=center_x+half_patch+1\n",
    "    end_y=center_y+half_patch+1\n",
    "   \n",
    "    new_patch=np.zeros((patch_s,patch_s))\n",
    "    \n",
    "    new_patch=image[start_x:end_x,start_y:end_y]  \n",
    "    \n",
    "    return(new_patch)\n",
    "\n",
    "def Extract_Patches(path_save,patch_s,X,Y):\n",
    "    \"\"\"\n",
    "    Extracts patches from the images and saves them in different batches \n",
    "    (makes it easier to load to memory)\n",
    "    All the patches from the minority class are extracted and the same number \n",
    "    of random patches are extracted from the majority class\n",
    "    Inputs:\n",
    "        path_save = path to save the extracted patches\n",
    "        patch_s = size of the extracted (squared) patches \n",
    "        X = images (n_images, img_size, img_size)\n",
    "        Y = labels (n_images, img_size, img_size)\n",
    "    Outputs:\n",
    "        No outputs, files are written to the specified directory\n",
    "    \"\"\"       \n",
    "    \n",
    "    num_images=X.shape[0]\n",
    "    lines_s=X.shape[1]\n",
    "    cols_s=X.shape[2]\n",
    "    \n",
    "    # accounts for the image borders \n",
    "    half_patch=int(patch_s/2)\n",
    "    end_l=lines_s-half_patch\n",
    "    end_c=cols_s-half_patch\n",
    "    \n",
    "    # goes through all images and extracts a patch for each postion where there is a membrane (label = 0)\n",
    "    for k in range(0,num_images):\n",
    "        print(\"Processing Image: \",k)\n",
    "        patches=list()\n",
    "        patches_labels=list()\n",
    "        for i in range (half_patch,end_l):\n",
    "            for j in range (half_patch,end_c):\n",
    "                if not Y[k,i,j]:\n",
    "                   patch=Get_Patch(i,j,patch_s,X[k,:,:])\n",
    "                   patches.append(patch)\n",
    "                   patches_labels.append(0)\n",
    "                      \n",
    "        total_patches=len(patches) # total number of patches extracted from the minority class\n",
    "        l=0\n",
    "        # we extract the same number of patches for the majority class\n",
    "        while (l<total_patches):        \n",
    "            i=randint(half_patch,end_l-1)\n",
    "            j=randint(half_patch,end_c-1)\n",
    "            if Y[k,i,j]:\n",
    "                   patch=Get_Patch(i,j,patch_s,X[k,:,:])\n",
    "                   patches.append(patch)\n",
    "                   l += 1\n",
    "                   patches_labels.append(1)\n",
    "        \n",
    "        name_patch=os.path.join(path_save,\"batch_\"+str(k)+\".npy\")\n",
    "        name_labels=os.path.join(path_save,\"labels_\"+str(k)+\".npy\")\n",
    "        patches=np.array(patches)\n",
    "        patches_labels=np.array(patches_labels)\n",
    "        np.save(name_patch,patches)\n",
    "        np.save(name_labels,patches_labels)\n",
    "    return()\n",
    "       \n",
    "    \n",
    "def Extract_Patches_Test(path_save,patch_s,X,Y):\n",
    "    \"\"\"\n",
    "    Extracts all possible the patches from the images (one for each pixel). \n",
    "    This function can be used to visualize the results and compute the DICE score.\n",
    "    Inputs:\n",
    "        path_save = path to save the extracted patches\n",
    "        patch_s = size of the extracted (squared) patches \n",
    "        X = images (n_images, img_size, img_size)\n",
    "        Y = labels (n_images, img_size, img_size)\n",
    "    Outputs:\n",
    "        No outputs, files are written to the specified directory\n",
    "    \"\"\"\n",
    "    \n",
    "    num_images=X.shape[0]\n",
    "    lines_s=X.shape[1]\n",
    "    cols_s=X.shape[2]\n",
    "    \n",
    "    #accounting for the borders of the patches\n",
    "    half_patch=int(patch_s/2)\n",
    "    end_l=lines_s-half_patch\n",
    "    end_c=cols_s-half_patch\n",
    "    \n",
    "    #goes through the image\n",
    "    for k in range(0,num_images):\n",
    "        print(\"Processing Image: \",k)\n",
    "        patches=list()\n",
    "        patches_labels=list()\n",
    "        for i in range (half_patch,end_l):\n",
    "            for j in range (half_patch,end_c):\n",
    "               patch=Get_Patch(i,j,patch_s,X[k,:,:])\n",
    "               patches.append(patch)\n",
    "               if Y[k,i,j]==0:\n",
    "                   patches_labels.append(0)\n",
    "               else:\n",
    "                   patches_labels.append(1)\n",
    "                           \n",
    "        name_patch=os.path.join(path_save,\"batch_test\"+str(k)+\".npy\")\n",
    "        name_labels=os.path.join(path_save,\"labels_test\"+str(k)+\".npy\")\n",
    "        patches=np.array(patches,dtype='float32')\n",
    "        patches_labels=np.array(patches_labels,dtype='float32')\n",
    "        np.save(name_patch,patches)\n",
    "        np.save(name_labels,patches_labels)     \n",
    "\n",
    "# If you run into memory problems, you may want to downsample the original images\n",
    "def resize_image(image, final_size):\n",
    "    ratio = np.array(image.shape)/np.array(final_size)\n",
    "    smoothed = sndim.gaussian_filter(image, sigma = ratio) # smooth the image first\n",
    "    return skimage.transform.resize(smoothed, final_size)\n",
    "        \n",
    "# Performance metrics\n",
    "def Dice(ground_truth,segmentation):\n",
    "    intersection=np.sum(segmentation[ground_truth==1]*2.0)\n",
    "    dice_coef=intersection/(np.sum(ground_truth)+np.sum(segmentation))\n",
    "    print(\"dice coef: \",dice_coef)\n",
    "    return(dice_coef)    \n",
    "    \n",
    "def Pixel_Error(ground_truth,segmentation):\n",
    "    bin_seg = 1 - (segmentation < .5)\n",
    "    pix_err=1 - ((bin_seg == ground_truth).sum()/ground_truth.size)\n",
    "    print(\"pixel error: \",pix_err )\n",
    "    return(pix_err)\n",
    "    \n",
    "def Score_AUC(ground_truth,segmentation):\n",
    "    ground_truth= np.reshape(ground_truth, (-1))\n",
    "    segmentation= np.reshape(segmentation, (-1))\n",
    "    auc=roc_auc_score(ground_truth,segmentation)\n",
    "    print(\"AUC: \",auc)\n",
    "    return(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the code below you can extract patches from the images. Make sure that the path to the shared folder is set properly. This is important because the VM doesn't have enough memory to store the patches you are going to extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shared_folder = r'/home/user/Desktop/Shared_Windows/winter_school_ml' # change this accordingly\n",
    "path_challenge = os.path.join(shared_folder, 'challenge') # path to the challenge data \n",
    "path_patches = os.path.join(path_challenge, 'Patches') # path to the location where the patches will be written\n",
    "\n",
    "# Creates patch folder, if it isn't there yet\n",
    "if not os.path.exists(path_patches):\n",
    "    os.makedirs(path_patches)\n",
    "\n",
    "# Extracts patches from all images, later they will be used for training and validating\n",
    "# Patches are size 15, this is something you can play with.\n",
    "patch_s = 15\n",
    "X=np.load(os.path.join(path_challenge,\"data.npy\"))\n",
    "Y=np.load(os.path.join(path_challenge,\"labels.npy\"))\n",
    "Extract_Patches(path_patches, patch_s, X, Y) \n",
    "\n",
    "# Extracts patches from a few images for later evaluation and visualization \n",
    "# (you shouldn't use them for training)\n",
    "Extract_Patches_Test(path_patches, patch_s, X[20:25,:], Y[20:25,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have created 25 batches of about 100k patches each. You can now train a classifier on them (we advise you to keep 20 for the actual training and 5 for testing, where you can evaluate hyperparameters, etc.). \n",
    "\n",
    "For example, you can use a CNN like the one you explored in [Tutorial-Part2](../tutorial/tutorial_part2-final.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_batches = 20 # number of training batches (you created one per original image)\n",
    "batch_size = 100 # number of training patches seen at each iteration of the optimizer\n",
    "epochs = 1 # number of iterations over the whole training set\n",
    "num_classes = 2 # number of classes\n",
    "\n",
    "# shape of each input patch (patch_size, patch_size, 1) - 1 channel for grayscale images\n",
    "patch_shape = (patch_s, patch_s, 1)\n",
    "\n",
    "#Here you can create your own CNN architecture (or your own approach)\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# Training is performed in batches: for each epoch, read a batch and feed it to the network\n",
    "for e in range(epochs):\n",
    "    for i in range(0,num_batches):\n",
    "        x = np.load(os.path.join(path_patches,\"batch_\"+str(i)+\".npy\"))\n",
    "        y = np.load(os.path.join(path_patches,\"labels_\"+str(i)+\".npy\"))\n",
    "        y=keras.utils.to_categorical(y,num_classes)\n",
    "        x=np.expand_dims(x,axis=3) \n",
    "        model.fit(x, y, batch_size=batch_size, nb_epoch=epochs, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have trained your model, you can apply it to make predictions on the test set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_ind = 0 # pick image index\n",
    "x = np.load(os.path.join(path_patches,\"batch_test\"+str(img_ind)+\".npy\"))\n",
    "x = np.expand_dims(x,axis=3) \n",
    "prob_segmentation=model.predict(x)\n",
    "prob_segmentation=np.reshape(prob_segmentation,(498,498,-1))[:,:,1]\n",
    "\n",
    "# ground truth labels\n",
    "y = np.load(os.path.join(path_patches,\"labels_test\"+str(img_ind)+\".npy\"))\n",
    "y = keras.utils.to_categorical(y,num_classes)\n",
    "y = np.reshape(y, (498,498,-1))[:,:,1] \n",
    "\n",
    "# binarize the probability map\n",
    "threshold = 0.5\n",
    "bin_segmentation = prob_segmentation > threshold\n",
    "\n",
    "# Calculates the performance metrics\n",
    "pix_er = Pixel_Error(y, bin_segmentation)\n",
    "dice = Dice(y, bin_segmentation)\n",
    "auc = Score_AUC(y, prob_segmentation) # for the AUC, the actual probabilities are used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also visualize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = np.reshape(x, (498,498,-1))[:,:,1] # reconstruct the image from the patches\n",
    "\n",
    "contours_ground_truth = skimage.segmentation.mark_boundaries(img, y > 0)\n",
    "contours_segmentation = skimage.segmentation.mark_boundaries(img, bin_segmentation)\n",
    "\n",
    "figure(figsize=(16,16))\n",
    "subplot(221)\n",
    "title('segmentation result', fontsize=18)\n",
    "imshow(bin_segmentation, cmap='gray')\n",
    "axis('off')\n",
    "subplot(222)\n",
    "title('ground truth', fontsize=18)\n",
    "imshow(y, cmap='gray')\n",
    "axis('off')\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! You have developed a segmentation method which will hopefully generalize well enough to be applicable to the validation data. If you're happy with it you can save it by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_model = os.path.join(path_challenge, 'my_amazing_model.h5')\n",
    "model.save(path_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See you tomorrow for the final competition!\n",
    "\n",
    "## ## Hands-on Session 3 - Award ceremony day\n",
    "By now you should have received the password to unlock the validation data. It is now time to evaluate your method and rank it against the other participants'. \n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to test the trained model on the validation set\n",
    "def Test_Validation(path_validation, model):\n",
    "    n_samples = 5\n",
    "    pix=np.zeros(n_samples)\n",
    "    dice=np.zeros(n_samples)\n",
    "    auc=np.zeros(n_samples)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        x = np.load(os.path.join(path_validation,\"batch_test\"+str(i)+\".npy\"))\n",
    "        y = np.load(os.path.join(path_validation,\"labels_test\"+str(i)+\".npy\"))\n",
    "        y = keras.utils.to_categorical(y,num_classes)\n",
    "        x = np.expand_dims(x,axis=3) \n",
    "        segmentation=model.predict(x)\n",
    "        y = np.reshape(y, (498,498,-1))[:,:,1] \n",
    "        segmentation=np.reshape(segmentation,(498,498,-1))\n",
    "        segmentation=segmentation[:,:,1]\n",
    "        pix[i] = Pixel_Error(y,segmentation)\n",
    "        dice[i] = Dice(y,segmentation)\n",
    "        auc[i] = Score_AUC(y,segmentation)\n",
    "    return(pix,dice,auc)\n",
    "\n",
    "# Extracts patches from the validation images\n",
    "path_validation = os.path.join(path_challenge, \"validation_data\")\n",
    "path_patches_validation = os.path.join(path_patches, \"validation_data\")\n",
    "if not os.path.exists(path_patches_validation):\n",
    "    os.makedirs(path_patches_validation)\n",
    "\n",
    "X = np.load(os.path.join(path_validation,\"data_validation.npy\"))\n",
    "Y = np.load(os.path.join(path_validation,\"labels_validation.npy\"))\n",
    "Extract_Patches_Test(path_patches_validation,patch_s,X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the model and test it on the validation data\n",
    "trained_model = load_model(path_model)\n",
    "pix,dice,auc = Test_Validation(path_patches_validation, trained_model)\n",
    "\n",
    "print(\"pixel error: %0.2f +/- %0.2f\" % (pix.mean(), pix.std()))\n",
    "print(\"Dice coefficient: %0.2f +/- %0.2f\" % (dice.mean(), dice.std()))\n",
    "print(\"Area Under the Curve: %0.2f +/- %0.2f\" % (auc.mean(), auc.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please let us know your results so that we can rank the groups!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
