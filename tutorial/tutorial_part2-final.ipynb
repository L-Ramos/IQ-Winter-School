{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iQ Winter School 2018 on Machine Learning Applied to Quantitative Analysis of Medical Images \n",
    "\n",
    "## Hands-on Session 1 - Tutorial\n",
    "## Part 2 - Convolutional Neural Networks (CNN)\n",
    "\n",
    "### 1. Import libraries\n",
    "\n",
    "First, we are going to import the libraries that will be used in this part of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "import sklearn.model_selection\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from pylab import *\n",
    "import skimage.transform, skimage.filters\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    rec = recall(y_true, y_pred)\n",
    "    prec = precision(y_true, y_pred)\n",
    "    return 2*((prec*rec)/(prec+rec))\n",
    "\n",
    "print(\"Hoorray, no import errors!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load data from the OASIS database.\n",
    "\n",
    "This is the same dataset we have used in the first part of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = np.load(r'data/subjects_masked_bfc_resc.npy')\n",
    "labels = np.load(r'data/labels.npy')\n",
    "nb_labels_class = np.bincount(labels)\n",
    "num_classes = nb_labels_class.size\n",
    "N_subjects = subjects.shape[0]\n",
    "N_features = subjects.shape[1]\n",
    "print(\"%d healthy, %d AD\" % ((labels==0).sum(), (labels==1).sum()))\n",
    "print(\"number of samples: %d, number of features: %d\" % (N_subjects, N_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to memory restrictions, we will need to downsample the 2D slices four times. To avoid aliasing artifacts, we will smooth the image prior to resampling.\n",
    "\n",
    "#### Downsample the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample the images\n",
    "subjects = subjects.reshape((137,176,176))\n",
    "new_shape = (44,44,1)\n",
    "subjects_ds = []\n",
    "for subj in range(subjects.shape[0]):\n",
    "    img = subjects[subj,:,:].reshape((176,176))\n",
    "    img = skimage.filters.gaussian(img, sigma=4)\n",
    "    subjects_ds.append(skimage.transform.resize(img, new_shape))\n",
    "subjects_ds = np.array(subjects_ds)\n",
    "                                                \n",
    "figure()\n",
    "imshow(subjects_ds[0,:,:,0], cmap='gray')\n",
    "axis('off')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will train a small CNN (the LeNet-5 with a few modifications) on a portion of the dataset and test it on the remaining samples.\n",
    "\n",
    "### 3. Train and test a small CNN\n",
    "\n",
    "We will first split and prepare the data for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into training and testing\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(subjects_ds, labels, test_size=0.2, stratify = labels)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a CNN and visualize it schematically. The architecture is similar to that of the LeNet-5 (Lecun '98)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some hyperparameters\n",
    "batch_size = 10 # number of training examples seen at each iteration of the optimizer\n",
    "epochs = 300 # number of iterations over the whole training set\n",
    "\n",
    "receptive_field_size = 5\n",
    "activation = 'relu' # Rectified Linear Unit\n",
    "pool_size = (2,2)\n",
    "nb_filters_conv1 = 12\n",
    "nb_filters_conv2 = 24\n",
    "nb_neurons_dense1 = 180 # 180 neurons in the first fully connected layer\n",
    "nb_neurons_dense2 = 100\n",
    "p_dropout = 0.5 # dropout of 50% of the neurons\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(nb_filters_conv1, receptive_field_size, receptive_field_size, \\\n",
    "                 activation = activation, input_shape=new_shape))\n",
    "model.add(MaxPooling2D(pool_size = pool_size))\n",
    "model.add(Dropout(p_dropout)) \n",
    "model.add(Conv2D(nb_filters_conv2, receptive_field_size, receptive_field_size, \\\n",
    "                 activation = activation))\n",
    "model.add(MaxPooling2D(pool_size = pool_size))\n",
    "model.add(Dropout(p_dropout)) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(nb_neurons_dense1, activation = activation)) \n",
    "model.add(Dropout(p_dropout))\n",
    "model.add(Dense(nb_neurons_dense2, activation = activation))\n",
    "model.add(Dropout(p_dropout))\n",
    "model.add(Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=[f1])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can train the network and plot the training and test errors over the specified number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=epochs, \\\n",
    "                    verbose=1, \\\n",
    "                    validation_data=(x_test,y_test))\n",
    "\n",
    "F1_random = nb_labels_class[1]/labels.size # random classification F1 score\n",
    "\n",
    "figure()\n",
    "plot(history.history['f1'], '-r', label='training')\n",
    "plot(history.history['val_f1'], '-b', label='test')\n",
    "plot(np.arange(epochs), np.ones(epochs)*F1_random, '--k', label = 'random')\n",
    "legend()\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ----- What's the effect of dropout regularization in the model's performance? What happens when you don't use it at all? What network hyperparameters have the highest impact?\n",
    "\n",
    "\n",
    "### 4. Data augmentation\n",
    "Besides regularization (like dropout), another common strategy to circumvent overfitting is to increase the size of the training set by performing data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Performs data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True)  # randomly flip images\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                                epochs=epochs,\n",
    "                                steps_per_epoch=40,\n",
    "                                verbose=0,\n",
    "                                validation_data=(x_test, y_test),\n",
    "                                workers=4)\n",
    "\n",
    "# Plots the learning curves\n",
    "figure()\n",
    "plot(history.history['f1'], '-r', label='training')\n",
    "plot(history.history['val_f1'], '-b', label='test')\n",
    "plot(np.arange(epochs), np.ones(epochs)*F1_random, '--k', label = 'random')\n",
    "legend()\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ----- Do all of the augmentation techniques used above make sense in this classification problem? What other transformations could you apply to the images to increase the training set size? How does the network perform compared to not doing any augmentation? \n",
    "\n",
    "### 5. Network visualization\n",
    "Finally, you may want to inspect the weights at a given layer in the CNN. Here, we show the weight matrices from the very first convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layer = model.layers[0] # selects the first convolutional layer\n",
    "weights = conv_layer.get_weights() # gets the layer's weights\n",
    "nb_filters = weights[1].size\n",
    "\n",
    "n = ceil(np.sqrt(nb_filters))\n",
    "figure(figsize=(12,12))\n",
    "for i in range(nb_filters):\n",
    "    w = weights[0][:,:,0,i]\n",
    "    subplot(n,n,i+1)\n",
    "    imshow(w, cmap='gray')\n",
    "    axis('off')\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These weights matrices have probably not added much information about how the network is learning. Another more useful thing you could do is visualize the actual layer outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_layer_output = K.function([conv_layer.input, K.learning_phase()],\n",
    "                                  [conv_layer.output])\n",
    "\n",
    "# Takes the first test image\n",
    "img = x_test[0,...][np.newaxis,...]\n",
    "\n",
    "# output in test mode -->  K.learning_phase() must be 0\n",
    "layer_output = get_layer_output([img, 0])[0]\n",
    "print(\"Shape of the output of the first convolutional layer: \", layer_output[0].shape) # 12 filter maps (40x40) after the first convolutional layer\n",
    "\n",
    "# Visualize the filter maps after the first Conv layer\n",
    "figure(figsize=(12,12))\n",
    "for i in range(nb_filters):\n",
    "    filter_map = layer_output[0][:,:,i]\n",
    "    subplot(n,n,i+1)\n",
    "    imshow(filter_map, cmap='gray', interpolation = None)\n",
    "    axis('off')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ----- What can you tell from these results? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
