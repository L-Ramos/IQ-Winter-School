{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iQ Winter School 2018 on Machine Learning Applied to Quantitative Analysis of Medical Images \n",
    "\n",
    "## Hands-on Session 1 - Tutorial\n",
    "## Part 1 - Machine Learning basics\n",
    "\n",
    "### 1. Import libraries\n",
    "\n",
    "First, we are going to import the libraries that will be used in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.ndimage as sndim\n",
    "from pylab import *\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import sklearn.model_selection, sklearn.linear_model, sklearn.metrics, sklearn.pipeline, \\\n",
    "sklearn.decomposition, sklearn.feature_selection, sklearn.ensemble, sklearn.cluster, \\\n",
    "skimage.segmentation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "  \n",
    "print(\"Hoorray, no import errors!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load data from the OASIS database.\n",
    "\n",
    "We are now going to load the dataset with which we are going to work throughout this tutorial. The data was retrieved and adapted from the OASIS database: http://www.oasis-brains.org/ and consists of coronal slices of T1-weighted brain scans acquired from both healthy subjects and patients with cognitive impairment (all diagnosed with \"probable Alzheimer's Disease\" - AD). The goal is to separate these two classes, which have been defined as follows:\n",
    "\n",
    "* label 0: cognitively healthy subjects, ie. a Clinical Dementia Rating (CDR) of 0\n",
    "* label 1: subjects with \"probable AD\", ie. a Clinical Dementia Rating (CDR) of 0.5 or 1\n",
    "\n",
    "The T1-images have been preprocessed: the skulls have been removed, the bias field that is often present in MR images has been corrected for and the images have been affinely registered to a brain template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the data into a numpy array\n",
    "subjects = np.load(r'data/subjects_masked_bfc_resc.npy')\n",
    "labels = np.load(r'data/labels.npy')\n",
    "\n",
    "# Counts the number of healthy subjects and AD patients and the number of features (pixels) per image\n",
    "nb_labels_class = np.bincount(labels)\n",
    "N_subjects = subjects.shape[0]\n",
    "N_features = subjects.shape[1]\n",
    "print(\"%d healthy, %d AD\" % (nb_labels_class[0], nb_labels_class[1]))\n",
    "print(\"number of samples: %d, number of features: %d\" % (N_subjects, N_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of the variable `subjects` corresponds to a subject and the columns are the individual pixels of the brain slice, all put together in a single row.\n",
    "\n",
    "The variable `labels` contains the class of each of the 137 subjects: 0 for healthy subjects, 1 for Alzheimer's patients.\n",
    "\n",
    "### 3. Visualize some examples\n",
    "\n",
    "Next, we are going to display some of the T1 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects the healthy subjects\n",
    "healthy_subjects = subjects[labels==0]\n",
    "\n",
    "# Selects AD patients\n",
    "ad_subjects = subjects[labels==1]\n",
    "\n",
    "# Creates figure for plotting\n",
    "fig = figure(figsize=(16,12))\n",
    "N = 6\n",
    "img_shape = (176,176)\n",
    "grid = ImageGrid(fig, 111,  nrows_ncols=(2, N), axes_pad=0.1) \n",
    "for i in range(N):\n",
    "    grid[i].imshow(healthy_subjects[i].reshape(img_shape), cmap='gray') # first row\n",
    "    grid[i+N].imshow(ad_subjects[i].reshape(img_shape), cmap='gray') # second row\n",
    "    grid[i+N].get_xaxis().set_ticks([])\n",
    "\n",
    "    if i == 0:\n",
    "        grid[i].get_xaxis().set_ticks([])\n",
    "        grid[i].get_yaxis().set_ticks([])\n",
    "        grid[i].set_ylabel('healthy')\n",
    "        \n",
    "        grid[i+N].get_yaxis().set_ticks([])\n",
    "        grid[i+N].set_ylabel('AD')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, and especially if we are planning to use the image pixel values directly as features, some standardization needs to be performed. This has already been done in this dataset, but it is still worth confirming that this is the case by taking a look at the image histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nbins = 100\n",
    "\n",
    "# Collects the histograms of all subjects\n",
    "histograms = np.zeros((N_subjects, Nbins))\n",
    "figure(figsize = (8,8))\n",
    "for i in range(N_subjects):\n",
    "    mask = subjects[i,:] > 0 # creates a brain mask (discard all background pixels)\n",
    "    h,b = np.histogram(subjects[i,:][mask], bins = Nbins, normed = True)\n",
    "    histograms[i,:] = h\n",
    "    plot(b[:-1],h)\n",
    "\n",
    "ylabel(\"histogram\")\n",
    "xlabel(\"pixel intensity\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image intensities are all within the same range and the three histogram modes are approximately aligned, indicating that the different tissue types (gray, white matter and cerebrospinal fluid) have similar intensity ranges across all patients.\n",
    "\n",
    "### 4. Logistic regression on the pixel values. \n",
    "\n",
    "One of the most basic linear classifiers is Logistic Regression. We will start by applying it to the pixel intensities. For a proper evaluation of the classifier, we will perform 3-fold cross-validation on the entire dataset of 137 samples. We opt for stratified folds, as the dataset is slightly imbalanced, thereby ensuring that the class proportions remain the same across all folds. To evaluate the performance of the classifier in each fold, we will use the F1 score, which takes both precision and recall into account.\n",
    "\n",
    "#### 4.1 Benchmark: Logistic Regression applied to the original pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes the Logistic Regression (LR) classifier\n",
    "log_reg = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "# Initializes the cross validation scheme with 3 folds\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits = 3)\n",
    "\n",
    "# Computes the F1 score on the test set for each cross-validation fold\n",
    "scores_logreg = sklearn.model_selection.cross_val_score(log_reg, subjects, labels, cv=cv, scoring='f1')\n",
    "print(\"scores in each CV fold: \", scores_logreg)\n",
    "print(\"average F1 score: %0.2f +/- %0.2f\" % (scores_logreg.mean(), scores_logreg.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ----- What happens when you increase the amount of folds in the cross validation scheme? Why is this?\n",
    "##### ----- What happens if you try a different cross-validation function? (ShuffleSplit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Overfitting\n",
    "\n",
    "Although this simple experiment gives an indication of how the classifier is performing on the test sets (for each cross-validation split), it is worth checking whether we are under- or overfitting (if at all). This will help us decide what to do next.\n",
    "\n",
    "A simple way of understanding the behavior of the classifier is to observe how the training and test performance scores vary as we increase the amount of training samples.\n",
    "\n",
    "We will then make the so-called \"learning curves\" for this classification problem. As a reference, we also plot the F1 score we would obtain if we would classify the samples randomly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = np.array([0.1,0.3,0.6,0.9]) # fraction of samples to be used for training\n",
    "train_sizes, train_scores, test_scores = sklearn.model_selection.learning_curve(log_reg, \\\n",
    "                                                                                subjects, \\\n",
    "                                                                                labels, \\\n",
    "                                                                                cv = cv, \\\n",
    "                                                                                train_sizes = train_sizes, \\\n",
    "                                                                                scoring = 'f1')\n",
    "\n",
    "F1_random = nb_labels_class[1]/labels.size # random classification F1 score\n",
    "\n",
    "figure(figsize=(8,8))\n",
    "title(\"Logistic Regression on the original pixel values\")\n",
    "xlabel(\"# Training examples\")\n",
    "ylabel(\"F1-Score\")\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training\")\n",
    "fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Test\")\n",
    "fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plot(train_sizes, np.ones(train_sizes.size) * F1_random, '--k', label = 'Random')\n",
    "legend()\n",
    "ylim(0.48,1.01)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we obtain perfect training performance (F1 score = 1) for all training set sizes, for the test set the classifier performs only slightly above random. This is a common indication that we are overfitting the data. In fact, we could already anticipate this, as the number of training samples we have is significantly smaller than the number of features (in our case, less than 137 subjects with ~30k pixel intensities).\n",
    "\n",
    "A straightforward way of avoiding overfitting would be to increase the amount of training samples. However, and just like in many other medical imaging applications, our dataset is limited.\n",
    "\n",
    "Another common strategy to prevent overfitting is to decrease the dimensionality of the problem, i.e., to reduce the number of features.\n",
    "\n",
    "We can achieve this by either selecting some of the pre-existing features or by extracting new features from the original ones. We will start by trying feature selection using univariate analysis on the original data. Basically, we will look at each pixel individually and see whether its intensity is statistically significantly different between the two classes.\n",
    "\n",
    "#### 4.3 Feature selection: univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([1, 10, 100, 1000, 10000, N_features]) # number of features to be selected/extracted\n",
    "n_plots = len(features)\n",
    "scores_avg = np.zeros(features.size)\n",
    "scores_std = np.zeros(features.size)\n",
    "\n",
    "# Iterates over the number of features \n",
    "for i,n_feats in enumerate(features):\n",
    "    # feature reduction line - change this for other types of feature selection/extraction\n",
    "    feature_red = sklearn.feature_selection.SelectKBest(k=n_feats) # univariate feature selection\n",
    "\n",
    "    # Applies a sequence of transforms: feature selection followed by Logistic Regression\n",
    "    pipeline = sklearn.pipeline.Pipeline([('feat reduction', feature_red), ('log reg', log_reg)])\n",
    "    \n",
    "    # Performs cross-validation\n",
    "    scores = sklearn.model_selection.cross_val_score(pipeline, subjects, labels, cv=cv, scoring='f1')\n",
    "    scores_avg[i] = scores.mean()\n",
    "    scores_std[i] = scores.std()\n",
    "    \n",
    "\n",
    "figure(figsize=(8,8))\n",
    "plot(np.log(features), scores_avg,'-o', label='feature reduction')\n",
    "fill_between(np.log(features), scores_avg - scores_std, scores_avg + scores_std, alpha=0.1, color=\"b\")\n",
    "plot(np.log(features), np.ones(len(features))*F1_random, '--k', label = 'Random')\n",
    "ylim(0.48,1.01)\n",
    "xlabel('# features')\n",
    "ylabel('F1 score (3-fold CV) on the whole dataset')\n",
    "legend()\n",
    "gca().set_xticks(np.log(features))\n",
    "gca().set_xticklabels(features)\n",
    "xticks(rotation=70)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, selecting statistically relevant features from the original dataset does not improve the performance. However, we observe that with 100 features the classifier performs only slightly worse than when all features are used, suggesting that redundant information is present in the feature set we are using. We could, then, decide to keep these 100 features and try to improve the performance of the classifier in some other way.\n",
    "\n",
    "What is typically also worth investigating is the location of the features that have been selected as \"most significant\". For example, if we search for the 100 most significant features and overlay them on one subject's image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects 100 features (pixels) \n",
    "feature_sel = sklearn.feature_selection.SelectKBest(k=100)\n",
    "feature_sel.fit(subjects,labels)\n",
    "\n",
    "sel_features = feature_sel.get_support() # returns a binary mask for the selected features\n",
    "sel_features_img = sel_features.reshape(img_shape) # reshapes the mask to the natural image shape\n",
    "sel_features_img = np.ma.masked_where(sel_features_img == 0, sel_features_img) # keeps only the selected features\n",
    "\n",
    "figure(figsize=(8,8))\n",
    "imshow(subjects[1,:].reshape(img_shape), cmap='gray')\n",
    "imshow(sel_features_img, cmap='autumn')\n",
    "axis('off')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... we observe that they are located near the ventricle boundaries and close to the hippocampus, which are areas typically affected in Alzheimer's patients. The pixel intensities here are capturing the brain shrinkage and the consequent increasing amount of cerebrospinal fluid (dark areas).\n",
    "\n",
    "We can also extract features from the original set of pixel intensities. This means that new features will be created, which may be more relevant for the classification we want to perform.\n",
    "\n",
    "#### 4.4 Feature extraction with PCA\n",
    "\n",
    "If you go back to the code where we performed feature selection, you can change one line to do feature extraction instead. A simple method for that is Principal Component Analysis (PCA), which linearly projects the data points into the directions of largest variance.\n",
    "\n",
    "##### ----- What sklearn function can you use to perform PCA? How different are the results compared to univariate feature selection? What are the disadvantages of extracting rather than selecting features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, instead of directly taking the pixel intensities as features, we can use the corresponding histograms (displayed at the very beginning of this tutorial) as feature vectors. This is a common way of summarizing the information contained in images.\n",
    "\n",
    "#### 4.5 Logistic Regression on the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_logreg = sklearn.model_selection.cross_val_score(log_reg, histograms, labels, cv=cv, scoring='f1')\n",
    "print(\"all scores (histograms): \", scores)\n",
    "print(\"average F1 score (histograms): %0.2f +/- %0.2f\" % (scores_logreg.mean(), scores_logreg.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ----- What other features do you think would be relevant for this classification task? Modify the code below accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_features = 2\n",
    "new_features = np.random.randn(N_subjects, nb_features) # random feature vectors\n",
    "#for i in range(N_subjects):\n",
    "    #new_features[i,0] = feature of interest 1 \n",
    "    #new_features[i,1] = feature of interest 2\n",
    "    #...\n",
    "scores_logreg = sklearn.model_selection.cross_val_score(log_reg, new_features, labels, cv=cv, scoring='f1')\n",
    "print(\"all scores (new features): \", scores_logreg)\n",
    "print(\"average F1 score: %0.2f +/- %0.2f\" % (scores_logreg.mean(), scores_logreg.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Support Vector Machine\n",
    "\n",
    "We will try now a Support Vector Machine (SVM) with a linear kernel. An important parameter in this classifier is the regularization parameter (C). Low C values correspond to highly regularized models (low penalty for training errors and consequently wider margins).\n",
    "\n",
    "We will take a look at what happens when we vary this parameter. In particular, we will compare the training and the test F1 scores, on a fixed training-test (50/50) split, at increasing C values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(subjects, \\\n",
    "                                                                            labels, \\\n",
    "                                                                            test_size=0.5, \\\n",
    "                                                                            random_state=0)\n",
    "\n",
    "# Creates an array of equally spaced numbers over a certain interval\n",
    "Cs = 10**np.linspace(-6,-1,6)\n",
    "training_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i,C in enumerate(Cs):\n",
    "    # Initializes the SVM model\n",
    "    linear_svm = sklearn.svm.SVC(kernel='linear', C=C)\n",
    "    \n",
    "    # Creates the model by fitting it to the data\n",
    "    linear_svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicts the training and test set labels\n",
    "    training_pred = linear_svm.predict(X_train)\n",
    "    test_pred = linear_svm.predict(X_test)\n",
    "    \n",
    "    # Saves the training and test scores for this iteration (one of the values of C)\n",
    "    training_scores.append(sklearn.metrics.f1_score(training_pred, y_train))\n",
    "    test_scores.append(sklearn.metrics.f1_score(test_pred, y_test))\n",
    "\n",
    "figure(figsize=(8,8))\n",
    "plot(np.log(Cs), training_scores,'-r', label='Training')\n",
    "plot(np.log(Cs), test_scores,'-b', label='Test')\n",
    "plot(np.log(Cs), np.ones(len(Cs))*F1_random, '--k', label = 'Random')\n",
    "ylim(0.48,1.01)\n",
    "xlabel('regularization parameter C')\n",
    "ylabel('F1 score')\n",
    "legend()\n",
    "gca().set_xticks(np.log(Cs))\n",
    "gca().set_xticklabels(Cs)\n",
    "xticks(rotation=70)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the effect of decreasing the amount of regularization (increasing C) on the learning curves: at low C values, the training and the test errors are similar, meaning that we are neither over- nor underfitting. We reach an optimum score on the test set at C=1e-3, after which the performance deteriorates, depite the increase in the training score.\n",
    "\n",
    "In practice, we would pick the \"best\" C parameter by performing a search over a set of possible values in a nested cross-validation within the training set.\n",
    "\n",
    "##### ----- We have been using the F1 score as a performance metric, but what are the individual precision and recall values? In which situations would you favor one over the other?\n",
    "##### ----- How can you find the best parameters for your model when many are available? (GridSearchCV)\n",
    "\n",
    "\n",
    "### 6. Decision boundaries\n",
    "\n",
    "When our problem is bi- or tri-dimensional, we are able to visualize the feature space and the decision boundary determined by the classifier. \n",
    "\n",
    "For illustration purposes, we will now keep the 2 most \"relevant\" features (after univariate feature selection) and apply both Logistic Regression and linear SVM to the whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects the two \"best\" features\n",
    "feature_sel = sklearn.feature_selection.SelectKBest(k=2)\n",
    "feature_sel.fit(subjects,labels)\n",
    "features_2D = feature_sel.transform(subjects)\n",
    "\n",
    "# Builds a 2D feature space in which the decision boundary will be calculated\n",
    "step_size = (features_2D.max() - features_2D.min())/1000\n",
    "xmin, xmax = features_2D[:,0].min() - step_size, features_2D[:,0].max() + step_size\n",
    "ymin, ymax = features_2D[:,1].min() - step_size, features_2D[:,1].max() + step_size\n",
    "xx, yy = np.meshgrid(np.arange(xmin, xmax, step_size),np.arange(ymin, ymax, step_size))\n",
    "\n",
    "# Applies the classifiers to the samples in the feature space\n",
    "log_reg.fit(features_2D, labels)\n",
    "logreg_labels = log_reg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "logreg_labels = logreg_labels.reshape(xx.shape)\n",
    "\n",
    "linear_svm = sklearn.svm.SVC(kernel='linear', C=1e5)\n",
    "linear_svm.fit(features_2D,labels)\n",
    "linear_svm_labels = linear_svm.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "linear_svm_labels = linear_svm_labels.reshape(xx.shape)\n",
    "\n",
    "# Plots the decision boundaries\n",
    "figure(figsize=(12,6))\n",
    "subplot(121)\n",
    "title('Logistic Regression')\n",
    "plot(features_2D[labels==0,0], features_2D[labels==0,1],'bo', markeredgecolor='black', label='healthy')\n",
    "plot(features_2D[labels==1,0], features_2D[labels==1,1],'ro', markeredgecolor='black', label='AD')\n",
    "contourf(xx, yy, logreg_labels, cmap='Paired', alpha=.5)\n",
    "xlabel('Feature 1')\n",
    "ylabel('Feature 2')\n",
    "legend()\n",
    "subplot(122)\n",
    "title('Linear SVM')\n",
    "plot(features_2D[labels==0,0], features_2D[labels==0,1],'bo', markeredgecolor='black', label='healthy')\n",
    "plot(features_2D[labels==1,0], features_2D[labels==1,1],'ro', markeredgecolor='black', label='AD')\n",
    "contourf(xx, yy, linear_svm_labels, cmap='Paired', alpha=.5)\n",
    "xlabel('Feature 1')\n",
    "legend()\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Logistic Regression and SVM with no kernel are linear classifiers. Sometimes it may be worth using more complex models that have more degrees of freedom to fit the data. Examples of non-linear classifiers include SVMs with kernels (e.g.: a Radial Basis Function - RBF), Random Forests (RF) or even K-Nearest Neighbors (kNN).\n",
    "\n",
    "We will now show what the decision boundary may look like for these non-linear classifiers when we apply them to the 2 best features selected above. The exact shapes depend on each classifier's specific hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the classifiers, trains them and applies them to the samples in the 2D feature space\n",
    "rbf_svm = sklearn.svm.SVC(kernel='rbf', C=100, gamma = 10)\n",
    "rbf_svm.fit(features_2D, labels)\n",
    "rbf_svm_labels = rbf_svm.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "rbf_svm_labels = rbf_svm_labels.reshape(xx.shape)\n",
    "\n",
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=10, max_depth=3)\n",
    "rf.fit(features_2D, labels)\n",
    "rf_labels = rf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "rf_labels = rf_labels.reshape(xx.shape)\n",
    "\n",
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(features_2D, labels)\n",
    "knn_labels = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "knn_labels = knn_labels.reshape(xx.shape)\n",
    "\n",
    "# Plots the decision boundaries\n",
    "figure(figsize=(14,6))\n",
    "subplot(131)\n",
    "title(\"RBF SVM\")\n",
    "plot(features_2D[labels==0,0], features_2D[labels==0,1],'bo', markeredgecolor='black', label='healthy')\n",
    "plot(features_2D[labels==1,0], features_2D[labels==1,1],'ro', markeredgecolor='black', label='AD')\n",
    "contourf(xx, yy, rbf_svm_labels, cmap='Paired', alpha=.5)\n",
    "legend()\n",
    "axis('off')\n",
    "subplot(132)\n",
    "title(\"Random Forest\")\n",
    "plot(features_2D[labels==0,0], features_2D[labels==0,1],'bo', markeredgecolor='black', label='healthy')\n",
    "plot(features_2D[labels==1,0], features_2D[labels==1,1],'ro', markeredgecolor='black', label='AD')\n",
    "contourf(xx, yy, rf_labels, cmap='Paired', alpha=.5)\n",
    "legend()\n",
    "axis('off')\n",
    "subplot(133)\n",
    "title(\"k-Neareast Neighbors\")\n",
    "plot(features_2D[labels==0,0], features_2D[labels==0,1],'bo', markeredgecolor='black', label='healthy')\n",
    "plot(features_2D[labels==1,0], features_2D[labels==1,1],'ro', markeredgecolor='black', label='AD')\n",
    "contourf(xx, yy, knn_labels, cmap='Paired', alpha=.5)\n",
    "legend()\n",
    "axis('off')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ----- Can you explain the different boundary shapes obtained by these three classifiers? What happens when you change the classifiers' hyperparameters (eg: $\\gamma$ for the RBF-SVM, maximum depth for the RF, number of neighbors for the kNN)?\n",
    "\n",
    "\n",
    "We can also compare the performance of these classifiers on a fixed training-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the samples into training (50%) and test (50%)\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(features_2D, \\\n",
    "                                                                            labels, \\\n",
    "                                                                            test_size=0.5, \\\n",
    "                                                                            random_state=0)\n",
    "\n",
    "training_scores = []\n",
    "test_scores = []\n",
    "for clf in [log_reg, linear_svm, rbf_svm, rf, knn]: # iterates over the previosuly defined classifiers\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_pred = clf.predict(X_train)\n",
    "    training_scores.append(sklearn.metrics.f1_score(train_pred, y_train))\n",
    "    test_pred = clf.predict(X_test)\n",
    "    test_scores.append(sklearn.metrics.f1_score(test_pred, y_test))\n",
    "\n",
    "# Plots the performance results\n",
    "figure(figsize=(8,8))\n",
    "bar(np.arange(1,6), training_scores, width = 0.1, color = 'r', label = 'training')\n",
    "bar(np.arange(1,6)+0.2, test_scores, width = 0.1, color = 'b', label = 'test')\n",
    "legend()\n",
    "gca().set_xticks(np.arange(1,6)+.1)\n",
    "gca().set_xticklabels([\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\", \"Random Forest\", \"k-Neareast Neighbors\"])\n",
    "xticks(rotation=70)\n",
    "ylabel('F1 score')\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 3D downsampled images\n",
    "\n",
    "Finally, we can take a look at what happens when, instead of using a single 2D slice per subject, we take the whole 3D volume. As we have memory restrictions, we will use 3D images that have been downsampled 4 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the (previously downsampled) 3D volumes \n",
    "subjects_3d = np.load(r'data/subjects_masked_bfc_3D_ds4.npy')\n",
    "img_shape_3d = (44,52,44)\n",
    "\n",
    "# Shows three orthogonal slices for one subject\n",
    "img = subjects_3d[0,:].reshape(img_shape_3d).transpose((2,1,0))\n",
    "figure(figsize=(12,12))\n",
    "subplot(131)\n",
    "imshow(img[22,::-1,:], cmap='gray')\n",
    "axis('off')\n",
    "title('transversal slice')\n",
    "subplot(132)\n",
    "imshow(img[::-1,36,:], cmap='gray')\n",
    "axis('off')\n",
    "title('coronal slice')\n",
    "subplot(133)\n",
    "imshow(img[::-1,:,22], cmap='gray')\n",
    "axis('off')\n",
    "title('sagittal slice')\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we apply Logistic Regression directly on the pixel intensities, similarly to what we've done at the beginning of this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = sklearn.linear_model.LogisticRegression()\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits = 5) # 5-fold cross-validation\n",
    "scores_logreg = sklearn.model_selection.cross_val_score(log_reg, subjects_3d, labels, cv=cv, scoring='f1')\n",
    "print(\"all scores: \", scores)\n",
    "print(\"average F1 score: %0.2f +/- %0.2f\" % (scores_logreg.mean(), scores_logreg.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... the F1-score is slightly higher (0.67) than when using one slice only (0.62), meaning that relevant information is present in other parts of the brain. \n",
    "\n",
    "##### ----- Feature selection/extraction would likely improve the performance even further. A more complex classifier would also probably perform better. Can you combine the techniques illustrated above as a final experiment on the 3D images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Clustering for image segmentation\n",
    "\n",
    "We now want to segment the brain images into three separate tissues: white matter, gray matter and cerebrospinal fluid. We don't have labeled data on which we could train a classifier, so we will do unsupervised classification.\n",
    "\n",
    "For that purpose we will use a basic clustering algorithm: K-Means. Also, in order to extract more information from the image, we will create two feature maps and use them as inputs for the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects one image\n",
    "subj_index = 5\n",
    "img = subjects[subj_index,:].reshape(img_shape)\n",
    "brain_mask = img > 0\n",
    "\n",
    "# Filters the image with a gaussian filter and the laplacian of a gaussian\n",
    "gaussian_map = sndim.gaussian_filter(img, sigma=1)\n",
    "laplace_map = sndim.gaussian_laplace(img, sigma=1)\n",
    "\n",
    "# Shows the two filtered images\n",
    "figure(figsize=(12,12))\n",
    "subplot(121)\n",
    "imshow(gaussian_map, cmap='gray')\n",
    "title('gaussian filtered image')\n",
    "axis('off')\n",
    "subplot(122)\n",
    "imshow(laplace_map, cmap = 'gray')\n",
    "title('laplacian filtered image')\n",
    "axis('off')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs K-Means clustering with 3 classes (clusters) using the gaussian and laplacian filtered \n",
    "# pixel intensities as features\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=3)\n",
    "labels_kmeans = kmeans.fit_predict(np.c_[gaussian_map[brain_mask], laplace_map[brain_mask]])\n",
    "clusters = np.zeros(img_shape, dtype=np.int8)\n",
    "clusters[brain_mask] = labels_kmeans + 1\n",
    "\n",
    "# Shows the obtained clusters and corresponding contours\n",
    "contours = skimage.segmentation.mark_boundaries(img, clusters)\n",
    "figure(figsize=(12,12))\n",
    "subplot(121)\n",
    "imshow(clusters)\n",
    "axis('off')\n",
    "subplot(122)\n",
    "imshow(contours)\n",
    "axis('off')\n",
    "\n",
    "# Show the 2D feature space and the clustering result (the colors are the same as in \n",
    "# the segmented brain image)\n",
    "figure(figsize=(8,8))\n",
    "plot(gaussian_map[clusters==1], laplace_map[clusters==1], 'ob')\n",
    "plot(gaussian_map[clusters==2], laplace_map[clusters==2], 'og')\n",
    "plot(gaussian_map[clusters==3], laplace_map[clusters==3], 'oy')\n",
    "xlabel('gaussian')\n",
    "ylabel('laplacian')\n",
    "axis('square')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ----- Why do the clusters have this specific shape?\n",
    "\n",
    "##### ----- Knowing that there is cortical shrinkage in Alzheimer's patients and that the gray matter/cerebrospinal fluid volume ratio is often affected, how could you build a feature set that incorporates that information? Can you test the classifiers used above on these features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_brain(brain_img):\n",
    "    # add code here\n",
    "    brain_labels = np.zeros(brain_img.shape, dtype=bool)\n",
    "    return brain_labels\n",
    "\n",
    "def extract_features(brain_labels, nb_features):\n",
    "    feature_vector = np.random.randn(nb_features)\n",
    "    # add code here\n",
    "    return feature_vector\n",
    "\n",
    "# Extracts features for each subject\n",
    "nb_features = 2\n",
    "new_features = np.random.randn(N_subjects, nb_features)\n",
    "for i in range(N_subjects):\n",
    "    brain_labels = segment_brain(subjects[i,...].reshape(img_shape))\n",
    "    new_features[i,:] = extract_features(brain_labels, nb_features)\n",
    "    #...\n",
    "\n",
    "# Classifies using logistic regression\n",
    "scores_logreg = sklearn.model_selection.cross_val_score(log_reg, new_features, labels, cv=cv, scoring='f1')\n",
    "print(\"all scores: \", scores_logreg)\n",
    "print(\"average F1 score: %0.2f +/- %0.2f\" % (scores_logreg.mean(), scores_logreg.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
